# extraction_programs.py
import os
import time
import requests
import pandas as pd
from gql import gql, Client
from gql.transport.requests import RequestsHTTPTransport

def extract_programs(filter_data: dict,
                    graphql_url="https://quadrige-core.ifremer.fr/graphql/public",
                    access_token = "2L7BiaziVfbd9iLhhhaq6MiWRKGwJrexUmR183GgiJx4:CA8375B7CF45E83F3B637FE97F8DA0F6263120AA9D58C6888A32111C766B054C:1|D6YumLYYbW2wWLoiFkGx++l1psS6BxzHCB5zm2mJRivNlAppnQOVWOZOX+y1C66pkFOxzvADjh7JT9yy2PwsAg==",
                    output_dir="output_programs"):
    """
    Lance une extraction de programmes et retourne l‚ÄôURL CSV fournie par Ifremer.
    """

    # Initialisation du client GraphQL
    transport = RequestsHTTPTransport(
        url=graphql_url,
        verify=True,
        headers={"Authorization": f"token {access_token}"}
    )
    client = Client(transport=transport, fetch_schema_from_transport=False)

    # -------------------------
    # 1) Construire la requ√™te executeProgramExtraction
    # -------------------------
    name = filter_data.get("name", "Extraction Programmes")
    monitoring_location = filter_data.get("monitoringLocation", "")
    if not monitoring_location:
      raise ValueError("Le champ 'monitoringLocation' est vide ‚Äî requ√™te annul√©e.")


    query = gql(f"""
    query {{
      executeProgramExtraction(
        filter: {{
          name: "{name}"
          criterias: [{{
            monitoringLocation: {{ searchText: "{monitoring_location}" }}
          }}]
        }}
      ) {{
        id
        name
        startDate
        status
      }}
    }}
    """)

    try:
        response = client.execute(query)
        task = response["executeProgramExtraction"]
        task_id = task["id"]
        print(f"[extract_programs] ‚úÖ Extraction lanc√©e (id={task_id}, nom={task['name']})")
    except Exception as e:
        raise RuntimeError(f"Erreur lors du lancement de l‚Äôextraction : {e}")

    # -------------------------
    # 2) Suivi du statut
    # -------------------------
    status_query = gql("""
    query getStatus($id: Int!) {
        getExtraction(id: $id) {
            status
            fileUrl
            error
        }
    }
    """)

    file_url = None
    while file_url is None:
        status_resp = client.execute(status_query, variable_values={"id": task_id})
        extraction = status_resp["getExtraction"]
        status = extraction["status"]
        print(f"[extract_programs] Statut : {status}")

        if status == "SUCCESS":
            file_url = extraction["fileUrl"]
            print(f"[extract_programs] ‚úÖ Fichier disponible : {file_url}")
        elif status in ["PENDING", "RUNNING"]:
            time.sleep(2)
        else:
            raise RuntimeError(f"T√¢che en erreur : {extraction.get('error')}")

    return file_url


def download_csv(file_url: str, name="Programmes", output_dir="output_test") -> str:
    """
    T√©l√©charge le CSV brut depuis l‚ÄôURL Ifremer.
    """
    os.makedirs(output_dir, exist_ok=True)
    file_path = os.path.join(output_dir, f"{name}_brut.csv")

    r = requests.get(file_url)
    r.raise_for_status()
    with open(file_path, "wb") as f:
        f.write(r.content)

    print(f"[extract_programs] ‚úÖ CSV brut t√©l√©charg√© : {file_path}")
    return file_path


def nettoyer_csv(input_path, output_path, monitoring_location_prefix: str):
    """
    Nettoie le CSV pour ne garder que :
      - les lignes o√π Lieu : Mn√©monique commence par monitoring_location_prefix
      - uniquement les colonnes utiles
      - suppression des doublons bas√©s sur Programme : Code
    """
    import pandas as pd

    df = pd.read_csv(input_path, sep=";", dtype=str)

    colonnes_requises = [
        "Lieu : Mn√©monique",
        "Programme : Code",
        "Programme : Libell√©",
        "Programme : Etat",
        "Programme : Date de cr√©ation",
        "Programme : Droit : Personne : Responsable : NOM Pr√©nom : Liste"
    ]
    for col in colonnes_requises:
        if col not in df.columns:
            raise ValueError(f"‚ùå Colonne manquante dans le CSV extrait : {col}")

    # Filtrage dynamique sur la base du monitoring location
    df_filtre = df[df["Lieu : Mn√©monique"].str.startswith(monitoring_location_prefix, na=False)]

    df_reduit = df_filtre[[
        "Programme : Code",
        "Programme : Libell√©",
        "Programme : Etat",
        "Programme : Date de cr√©ation",
        "Programme : Droit : Personne : Responsable : NOM Pr√©nom : Liste"
    ]]
    df_unique = df_reduit.drop_duplicates(subset=["Programme : Code"])

    df_unique.to_csv(output_path, sep=";", index=False)
    print(f"[extract_programs] ‚úÖ CSV filtr√© enregistr√© : {output_path}")



def csv_to_programmes_json(csv_path: str):
    """
    Charge un CSV filtr√© et le transforme en liste JSON de programmes.
    """
    if not os.path.exists(csv_path):
        return []

    df = pd.read_csv(csv_path, sep=";", dtype=str).fillna("")

    programmes = []
    for _, row in df.iterrows():
        programmes.append({
            "name": row.get("Programme : Code", ""),
            "checked": False,
            "libelle": row.get("Programme : Libell√©", ""),
            "etat": row.get("Programme : Etat", ""),
            "startDate": row.get("Programme : Date de cr√©ation", ""),
            "responsable": row.get("Programme : Droit : Personne : Responsable : NOM Pr√©nom : Liste", "").replace("|", ", ")
        })
    return programmes


def sauvegarder_derniere_version(filtre_path: str, save_dir="output_test"):
    """
    Copie le CSV filtr√© vers last_programmes_updates.csv
    """
    os.makedirs(save_dir, exist_ok=True)
    dest_path = os.path.join(save_dir, "last_programmes_updates.csv")

    with open(filtre_path, "rb") as src, open(dest_path, "wb") as dst:
        dst.write(src.read())

    print(f"[extract_programs] üíæ Copie effectu√©e vers {dest_path}")
    return dest_path




# -------------------------
# Mode test (remplace list_programs.py)
# -------------------------
if __name__ == "__main__":
    # Exemple de filtre
    filtre = {
        "name": "Programmes_126",
        "monitoringLocation": "126-"
    }

    # √âtape 1 : extraction ‚Üí r√©cup√®re l‚ÄôURL CSV
    file_url = extract_programs(filtre)

    # √âtape 2 : t√©l√©chargement du brut
    csv_brut = download_csv(file_url, name=filtre["name"], output_dir="output_test")

    # √âtape 3 : nettoyage
    csv_filtre = "output_test/Programmes_126_filtered.csv"
    nettoyer_csv(csv_brut, csv_filtre,filtre["monitoringLocation"])

    print(f"[MAIN] ‚úÖ Extraction termin√©e, fichier filtr√© disponible : {csv_filtre}")
